{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informed-edgar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(5) <-> Node(10) <-> Node(1) <-> Node(7) <-> Node(8) <-> Node(2)\n",
      "head: Node(5)\n",
      "tail: Node(2)\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, value, before=None, after=None):\n",
    "        self.value = value\n",
    "        self.before = before\n",
    "        self.after = after\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Node({self.value})'\n",
    "\n",
    "HEAD = Node(\n",
    "    5,\n",
    "    before=None,\n",
    "    after=Node(\n",
    "        10, \n",
    "        before=None,\n",
    "        after=Node(\n",
    "            1, \n",
    "            before=None,\n",
    "            after=Node(\n",
    "                7, \n",
    "                before=None,\n",
    "                after=Node(\n",
    "                    8, \n",
    "                    before=None,\n",
    "                    after=Node(\n",
    "                        2, \n",
    "                        before=None,\n",
    "                        after=None,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Complete the list\n",
    "current_node = HEAD\n",
    "next_node = current_node.after\n",
    "while next_node:  \n",
    "    next_node.before = current_node\n",
    "    current_node = next_node\n",
    "    next_node = current_node.after\n",
    "\n",
    "\n",
    "nodes = []\n",
    "current_node = HEAD\n",
    "TAIL = None\n",
    "while current_node:\n",
    "    nodes.append(repr(current_node))\n",
    "    current_node = current_node.after\n",
    "    if current_node:\n",
    "        TAIL = current_node\n",
    "\n",
    "print(' <-> '.join(nodes))\n",
    "print('head:', HEAD)\n",
    "print('tail:', TAIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition: always more than 5 nodes\n",
    "# condition: no two nodes are the same, no overlapping node, Acyclic graph'\n",
    "# return value: middle nodes, not the values\n",
    "# condition: iterate through nodes from both sides, stop when nodes are equal\n",
    "       # - stop if node.after = other_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "checked-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_middle_nodes(head: Node, tail: Node) -> []:\n",
    "    p1 = head\n",
    "    p2 = tail\n",
    "\n",
    "    while p1 and p2:\n",
    "        if p1 == p2:\n",
    "            return [p1]\n",
    "        elif p1.after == p2:  # p1 == p2.before\n",
    "            return [p1, p2]\n",
    "        else:\n",
    "            p1 = p1.after\n",
    "            p2 = p2.before\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inner-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_middle_nodes(HEAD, TAIL) == [HEAD.after.after, HEAD.after.after.after]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-pitch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging system\n",
    "# logs need to be shipped to a central logging place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "- shipping logs to central store\n",
    "- where are thes logs coming from\n",
    "    24 regions per cloud provider, 1000 clusters per region, 3 nodes per cluster\n",
    "- how large are logs/ rate of log production\n",
    "  - 50 MB / hour\n",
    "    \n",
    "24 * 1000 * 3  * 50 mb / hour -> 3.4332275390625 / hr -> 1 GB / s -> 8 Gb / s\n",
    "\n",
    "- max latency, how many seconds? 5s\n",
    "\n",
    "inter datacenter bandwith rate is 1 Gb / s\n",
    "    \n",
    "- any formatting / parse\n",
    "  - No, compute \n",
    "- how freq we need to ship logs\n",
    "   - continuously\n",
    "- do we need to ship multiple logs at once\n",
    "   - yes\n",
    "- Do we need to maintain order? \n",
    "  - timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "verified-collaboration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(24 * 1000 * 3  * 50) / 1024 / 3600 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-vessel",
   "metadata": {},
   "source": [
    "injgestion \n",
    "  - LB \n",
    "    - Store nodes\n",
    "\n",
    "    \n",
    "shipping software on each node\n",
    "- 50 mb/ hour\n",
    "- are the processes going to go up and down, restart, reliablity\n",
    "- Single processs: are ther multiple writes to files\n",
    "- Are we writing to disk on nodes, we need to know if the disk can handle 50mb /hr, or can we store all in memory? If so, how much can we loose when a mchine dies. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
